# ü§ñ Assistente Universit√°rio RAG (Retrieval-Augmented Generation)

Este reposit√≥rio cont√©m o c√≥digo-fonte para um sistema de Perguntas e Respostas (QA) factual baseado na arquitetura **Retrieval-Augmented Generation (RAG)**. O objetivo √© fornecer respostas precisas a perguntas sobre documentos regulat√≥rios/universit√°rios (resolu√ß√µes), utilizando o conte√∫do **estritamente** indexado de arquivos PDF pr√©-processados.

O projeto utiliza a biblioteca `langchain` para orquestra√ß√£o, suportando dois _backends_ de Large Language Models (LLMs): **Google Gemini (via API)** e **Meta Llama-3.1 (HuggingFace local)**.

## üåü Vis√£o Geral

O _workflow_ do projeto √© dividido em tr√™s etapas principais:

1.  **Pr√©-processamento e Padroniza√ß√£o:** Extra√ß√£o de texto de PDFs (removendo texto riscado, normalizando formata√ß√£o) e divis√£o em _chunks_ por artigo/cap√≠tulo.
2.  **Indexa√ß√£o (Build FAISS):** Cria√ß√£o de um √≠ndice vetorial FAISS a partir dos _chunks_ textuais usando embeddings multilingual-e5-base.
3.  **Chatbot (RAG):** Implementa√ß√£o de uma _chain_ de QA que recupera informa√ß√µes do √≠ndice FAISS e as utiliza como contexto para o LLM responder de forma factual.

## üì¶ Estrutura do Reposit√≥rio

| Arquivo                                | Descri√ß√£o                                                                                                                                                              |
|:---------------------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| `Padronizador_Documentos_Corrigido.py` | Pipeline de extra√ß√£o, limpeza (remo√ß√£o de texto riscado/alterado), normaliza√ß√£o e _chunking_ de PDFs em arquivos Markdown por Artigo/Cap√≠tulo.                         |
| `build._faiss.py`                      | Script para criar o √≠ndice vetorial FAISS a partir dos arquivos Markdown gerados pelo padronizador, utilizando o modelo de embeddings `intfloat/multilingual-e5-base`. |
| `chatbot_Gemini.py`                    | Implementa√ß√£o da _chain_ RAG usando o modelo **Gemini 2.5 Pro** via API do Google.                                                                                     |
| `chatbot.py`                           | Implementa√ß√£o da _chain_ RAG usando o modelo **Llama 3.1 8B Instruct** rodando localmente (ou em GPU via `device_map="auto"`).                                         |
### Dados e Resultados

| Diret√≥rio | Descri√ß√£o |
|:---|:---|
| `Resultados_Gemini/` | Cont√©m os arquivos CSV gerados com as m√©tricas de avalia√ß√£o do RAGAS utilizando o modelo Gemini. |
| `Resultados_Llama_8B/` | Cont√©m os arquivos CSV gerados com as m√©tricas de avalia√ß√£o do RAGAS utilizando o modelo Llama 3.1 8B. |
| `Graficos_Comparativos/` | Pasta de sa√≠da onde s√£o salvos os gr√°ficos comparativos (PNG) gerados pelos scripts de visualiza√ß√£o. |